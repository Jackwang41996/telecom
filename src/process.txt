      
                       电信预购项目总结
总体需求：
以电信用户上网行为日志为基础的预购分析系统，基于移动上网数据的预购（购车、购房）行为分析设计。
系统将用户浏览信息进行基础行为解析及专题产品解析。对用户进行行为画像识别用户分类喜好；对专题产品识别，分析用户产品喜好并对用户关注产品进行智能推荐（猜你喜欢）。
总体模块：
1、数据处理：通过MapReduce处理数据（数据过滤、清洗、匹配、统计计算）
2、算法分析：用spark mlib算法库实现算法业务（ALS协同过滤、推荐）
环境描述：
操作系统：centos6.8
数据存储：hadoop 2.7.4
JDK:Jdk1.8.0_131
开发环境：eclipse+IEDA2017.2.3
数据处理：spark-2.1.2
配置数据：
行为地址基础数据t_dx_basic_msg_addr.txt
029195000008000000|mop.com|tt.mop.com|2|0|0
行为id 一级域名 匹配地址 匹配级别 是否产品标识 预购类型
产品地址基础数据t_dx_product_msg_addr.txt
029756000001000010|car|car000001|DS-DS 6-无限制|DS|16.39-30.19万|DS 6|欧系其他|无限制
行为id 产品类型 产品id 产品名称 产品特征值1 产品特征值2 产品特征值 3 产品特征值4 产品特征值5
行为分类基础数据t_dx_basic_classify_link.txt
00001|041401000000000000
行为分类id 行为id
产品地址分类数据car_type.txt
1|car000001|1
产品分类id 产品id 产品类型
行为数据分词数据basic_word_split.txt
000001000000000000,互联网|产品|保险|平台|推广|网|零零
行为id 分词列表
原始数据：
访问日期 用户标识 流量类型 开始时间 结束时间 时长（秒） 上行流量（bytes） 下行流量（bytes） 总流量（bytes） 源IP 目的IP 状态码 源端口 目的端口 网址/特征信息
开发过程：
一、原始数据清洗
1）去除数据中格式不符数据
2）去除非用户行为数据
3）清除图片数据清除格式
用户号码、一级域名、url地址
513047538993,ymby168.com,http://muhe.ymby168.com:8066/ct.php?hash=dcbb9e05db
开发过程：在本阶段难点是对数据的判断，以此来得到符合要求的数据，主要是正则表达式的编写 
二、行为匹配
行为匹配：识别清洗后保留数据的行为信息
匹配后字段说明：行为id，用户号码，是否产品,预购类型，url
523046669407,002974000000000000,0,0,http://nav.gionee.com/lockimage/logUpload.do?f=1&lan=zh&mcc=460&v=1.2.0.ck&t=1498877023538&s=C6B10F952FB1500A738AABEC4936E82B
这个阶段需要做一个表的关联，行为地址基础数据t_dx_basic_msg_addr.txt，我们把清洗后的数据关联后可以得到一个，用户行为匹配表
这个阶段最难的就是如何匹配地址，我们需要对清洗后的一级域名和行为地址库中的域名匹配，这个过程有一个匹配级别的问题，Map<String, TreeMap<String, String>> promap = new HashMap<String, TreeMap<String, String>>()，我用的是map中写TreeMap的方案，把一级域名写入key把后面的所有写入TreeMap得key,匹配时先匹配一级域名再匹配全域名，重写TreeMap中的排序方法可以实现降序，最后按降序输出结果
三、用户行为统计输出数据
字段注释：行为id， 用户号码，访问次数
4510002507,001914000000000000,20
这张表是对用户行为匹配表的的统计，统计用户对某个网站的访问次数
四、行为统计输出数据
行为id，访问人数（uv），访问次数（pv）
000042000000000000,23,1
这张表是根据用户行为统计数据表做的统计，统计出某个网页的pu值，用户数即为访问人数，每个用户访问次数的累加就是访问次数
五、产品匹配输出数据
字段注释：用户id，产品类型，产品id，产品特征值….，行为id
003942000037000113|house|house000044|其他-null-70平米到100平米|其他|300万以上|null|null|70平米到100平米|513042437238
这张表是通过关联t_dx_product_msg_addr.txt
029756000001000010|car|car000001|DS-DS 6-无限制|DS|16.39-30.19万|DS 6|欧系其他|无限制
在这张表的基础上增加一个字段，用户id，为了保证用户id的完整性，我们可以关联用户id最全的表，行为匹配表
003942000037000113|house|house000044|其他-null-70平米到100平米|其他|300万以上|null|null|70平米到100平米|513042437238
六、用户产品统计输出数据 
 统计用户高频访问地址  
字段注释：产品id，用户id，访问次数，产品类型
car,car000466,513049888252,1
这个过程是在产品匹配表的基础上做一个统计，统计某一个用户对某一产品访问次数
七、产品统计输出数据
字段注释：产品id，访问人数，访问次数
car000466,1,1
统计出每个产品的访问人数，和一共的访问次数
八、用户行为top提取
字段注释：行为id，用户id，访问次数，访问次数排名
693049165753,060071000000000000,2,060072000000000000,1,
这个表是在用户行为统计输出表的基础上做一个排序，这个阶段的难点是怎么把相同用户对不同网页的访问次数排序，我在这个阶段用到了之前学到二次排序，我通过自定义分区分组，把相同用户化为一组，然后利用二次排序，对相同用户访问的不同网页访问量进行排序，取前5输出
九、用户画像统计输出数据
统计每个用户访问某个行为分类的次数，和这个行为分类的总次数，及标准值（数据归一化）
字段注释：用户id，行为分类，用户访问次数，分类总访问次数，标准值（用于展示）
5063936616,00001,12,25007,-0.1808559192519587
这个阶段我们同样是在用户行为统计输出表的基础上操作，因为用户行为统计输出表包含了行为id， 用户号码，访问次数，行为id在t_dx_basic_classify_link.txt中，所以需要做表关联该表中将所有行为分为6类从00001到00006
这个阶段在重要的是key的选择，因为我们需要同时统计用户访问次数和分类总访问次数，我的key：分类ID；value：用户ID，访问次数，这样会把相同分类的拉近一个reduce，在reduce中把value拆分分别统计用户数，和分类总访问数，这样我们把得到的数据套入公式，做标准化处理就可以得到结果
标准值处理：由于单个用户对单个行为分类的访问次数量级不一样，这样做的话对后期的数据展示影响较大，展示的效果不好，所以需要将数据进行归一处理，本需求归一处理采用的是z-score标准差计算（反映数据集的离散程度，公式：（原数据-均值）/标准差）
均值=行为分类总次数/行为分类总人数
标准差:等同于数学中的标准差求解

十、预购用户群输出数据
字段注释：用户id，产品类型：访问次数
4510174246|2:2
这个表是在行为匹配表的基础上处额理的，同样因为匹配后的表中数据最全，减少了数据丢失，我们只要做一个统计即可
十一、协同过滤推荐输出数据
要想使用ALS算法首先要满足它的特点
ALS所处理的文件格式一般有三个字段user代表客户，items代表商品，vlaues代表打分
用户产品统计输出数据
car000002|533037532945|2|car
产品id，用户id，访问次数，产品类型
在这张表中我们可以得到所需要的三个字段，我们利用这张表训练处ALS模型，利用训练模型做预测，这个过程为了保证数据的唯一性，我们需要做hash处理，得到的结果也是hash值，我们通过join来还原数据最终的到结果
字段注释：用户id，预购类型，推荐产品id列表
(593050190695,1,car000321,car000314,car000287,car000107,car000064)
智能推荐：ALS协同过滤


